**Problem Statement:** 

In today's digital age, the rise of fake images has become a growing concern, as they can spread misinformation and erode public trust in media. In 2017, the term “deepfake” emerged to describe synthetic images and videos generated using deep learning technologies [1]. One of the most common applications of this technology is face-swapping, where a person’s face is realistically replaced in photos or videos. While this has creative uses, it has also become a tool for scammers and malicious actors, enabling identity manipulation, financial fraud, and political deception [2]. Using someone’s face without their explicit consent for personal, commercial, or political purposes violates core ethical principles in artificial intelligence [3]. The rapid advancement of AI has fueled progress in image generation techniques, such as Autoencoders and Generative Adversarial Networks (GANs), making it increasingly difficult to tell real faces from fake ones.

**Deepfake Image Example:**

![1.png](attachment:47c06ccb-bbe5-442d-89db-8f90f4f3daf6.png)

*Credits: Jennifer Lawrence + Steve Buscemi + Deepfake Image Generator => This Deepfake Image!*

**Dataset Description:** I used a pre-processed dataset of real and fake face images, resized to 224×224 pixels, from the Deepfake Detection Challenge (2019–2020) a collaboration between Meta, AWS, Microsoft, and the Partnership on AI’s Media Integrity Steering Committee to train this "DeepFake" model.
